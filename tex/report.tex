%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University/School Laboratory Report
% LaTeX Template
% Version 3.1 (25/3/14)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Linux and Unix Users Group at Virginia Tech Wiki 
% (https://vtluug.org/wiki/Example_LaTeX_chem_lab_report)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a4paper]{article}

\usepackage[margin=1 in]{geometry}
\usepackage{listings}
\usepackage{graphicx} % Required for the inclusion of images
\usepackage{natbib} % Required to change bibliography style to APA
\usepackage{amsmath} % Required for some math elements 

%\setlength\parindent{0pt} % Removes all indentation from paragraphs

%\renewcommand{\labelenumi}{\alph{enumi}.} % Make numbering in the enumerate environment by letter rather than number (e.g. section 6)


%----------------------------------------------------------------------------------------
%	DOCUMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Final project report on \\Path Finding Problem \\~ \\ CS 7750} % Title

\author{Zolbayar Magsar \\Chanmann Lim \\Yihan Xu}

\date{December 15, 2014}

\begin{document}

\maketitle % Insert the title, author and date

\lstset{language=Java,title=\lstname,basicstyle=\footnotesize}

\begin{center}
Electrical \& Computer Engineering \\
University of Missouri, Columbia \\
\vspace{.5 in}
Instructor: Dr. Yi Shang \\
\end{center}

\vspace{1 in}

% If you wish to include an abstract, uncomment the lines below
\begin{abstract}
In many occasions, we face the problem of finding a path from one place to another place. In such situations, were we not just trying to find the shortest distance; but the traveling time also an important factor to be taken into consideration. In artificial intelligence, search algorithms are mainly used for such problems. On the other hand, when it comes to differentiating between such algorithms, it is often useful to implement them on a path finding problem and compare their features. We have attempted to create a game map which can be used in a simple path finding problem. On the map, we have two points, source and destination. We are also free to create an arbitrary shape of walls between them to create a problem. We then have myriad of ways to examine the precise difference between search algorithms and compare them in terms of execution speed, accuracy, and overall performance. To solve the path finding problem, we have implemented six major search algorithms representing 3 main types of search algorithm families, namely Breadth-First Search, Depth-First Search, Greedy Best-First Search, A* Search, Hill-Climbing, and Simulated Annealing. The map is created using a grid structure, so as to have a precise depiction of the 'search movements' of each of the algorithms visually in terms of characteristics and performance.
\end{abstract}

% \vfill

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Introduction}

Wikipedia describes the pathfinding problem as "\emph{Pathfinding} or \emph{pathing} is the plotting, by a computer application, of the shortest route between two points". There are two main problems of pathfinding, which are:

\begin{itemize}
	\item Finding a path between two nodes in a graph 
	\item Finding the optimal path
\end{itemize}

\noindent Blind search algorithms such as breadth-first and depth-first search solve the first type of problem by exhaustively checking all possibilities, starting with the given node. They iterate through all possible paths until they find the destination node. Because of their “blindness”, such algorithms can be either ineffective or too expensive. \\

\noindent Then we have an even more complicated problem – finding the optimal path. In this case however, it is not required to check all possible paths in order to find the optimal one. By using heuristics (additional knowledge of the problem space), we can strategically eliminate unnecessary paths. We will find out that this informed approach is more powerful and "gets the job done" efficiently most of the time. \\

\noindent We also have a type of search algorithms that try to explore the search space unsystematically. This is relative to the fact that, in some problems, the path to the goal is irrelevant – what matters is the final state after the search effort. Local search algorithms are such algorithms in which the paths followed are not retained. \\
 
\noindent We have implemented six different algorithms reflecting the above three different approaches: \\
\begin{itemize}
	\item Uninformed search
	\begin{itemize}
		\item Breadth-first search
		\item Depth-first search
	\end{itemize}

	\item Heuristic search
	\begin{itemize}
		\item Greedy best-first search
		\item A* search
	\end{itemize}

	\item Local search
	\begin{itemize}
		\item Hill-climbing search
		\item Simulated annealing
	\end{itemize}
\end{itemize}

% \subsection{Definitions}
% \label{definitions}
% \begin{description}
% \item[Stoichiometry]
% The relationship between the relative quantities of substances taking part in a reaction or forming a compound, typically a ratio of whole integers.
% \item[Atomic mass]
% The mass of an atom of a chemical element expressed in atomic mass units. It is approximately equivalent to the number of protons and neutrons in the atom (the mass number) or to the average number allowing for the relative abundances of different isotopes. 
% \end{description} 
 
%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{Algorithms and Implementations}

There will be obstacles between the source and the destination squares, and our implementation shows graphically how each algorithm manage to reach the destination in its own term. This very activity will in turn allow us to visually enjoy the actual performance of each of those algorithms in real world problems. We made use of Manhattan distance heuristics for the informed search algorithms and as the scoring/objective function for local searches.

%----------------------------------------------------------------------------------------
%	Breadth-first
%----------------------------------------------------------------------------------------

\subsection{Breadth-first search algorithm:}

BFS is a  strategy for searching in a graph  when search is limited to essentially two operations: (a) visit and inspect a node of a graph; (b) gain access to visit the nodes that neighbor the currently visited node. The BFS begins at a root node and inspects all the neighboring nodes. Then for each of those neighbor nodes in turn, it inspects their neighbor nodes which were unvisited, and so on. \\

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.9]{images/bfs1.png}
  \caption{BFS with a block between two points}
\end{figure}

\noindent \\
The algorithm uses a queue data structure to store intermediate results as it traverses the graph, as follows:\\

\begin{enumerate}
\item Enqueue the root node
\item Dequeue a node in first-in-first-out manner and examine it
	\begin{itemize}
		\item If the element sought is found in this node, quit the search and return a result.
		\item Otherwise enqueue any successors (the direct child nodes) that have not yet been discovered.
	\end{itemize}
\item If the queue is empty, every node on the graph has been examined – quit the search and return "not found". \\
\item If the queue is not empty, repeat from Step 2.
\end{enumerate}

%----------------------------------------------------------------------------------------
%	Depth-first
%----------------------------------------------------------------------------------------

\subsection{Depth-first search algorithm:}

DFS starts at the root (selecting some arbitrary node as the root in the case of a graph) and explores as far as possible along each branch before backtracking. \\

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.9]{images/dfs1.png}
  \caption{DFS with a block between two points}
\end{figure}

\noindent \\
DFS always expands the deepest node in the current frontier of the search tree. As seen above, the search proceeds immediately to the deepest level of the search tree, where the nodes have no successors.

%----------------------------------------------------------------------------------------
%	Greedy best-first
%----------------------------------------------------------------------------------------

\subsection{Best-first search algorithm:}

It is a search algorithm which explores a graph by expanding the most promising node chosen solely according to additional knowledge about the problem given by its designer in term heuristic function.\\

\noindent We used "best-first search" to refer specifically to a search with a heuristic function that attempts to predict how close the end of a path is to a solution, so that paths which are judged to be closer to a solution are extended first. This specific type of search is called \textbf{greedy best-first search}. \\

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.9]{images/greedy1.png}
  \caption{Greedy best-first search with a block between two points}
\end{figure}

\noindent \\
By using a greedy algorithm, we expand the root and add its successors to the queue then pick the successor that is the closest to the goal node depend entirely on the prediction of the heuristic function.

\paragraph{Manhattan distance heuristic: } Think of the grid map, the root node, and goal node in our PathFinding program as a cartesian plane with two separate points $x$ and $y$. What is your best estimate about the distance from $x$ to $y$? One might give the straight-line distance (euclidean distance) estimate however the sum of the difference between $x$ and $y$ coordinates (manhattan distance) would yield a more admissible prediction and in fact it is the perfect estimate as we define our grid to allow only horizontal and vertical move but not diagonal or straight a cross every square.  

%----------------------------------------------------------------------------------------
%	A*
%----------------------------------------------------------------------------------------

\subsection{A* search algorithm:}

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.9]{images/A1.png}
  \caption{A* with a block between two points}
\end{figure}

\noindent As compared to the Best-first search algorithm, A* explores a graph not only by expanding the most promising node based on the heuristic function, but also on take into account the cost to reach that intermediate node itself. We made use of the Manhattan distance heuristic function with A* search. Since Manhattan distance is a consistent heuristic, we are guaranteed to find an optimal path in case of A*. \\

\noindent The key difference from the implementation of Best-first search is that we keep a sorted priority queue (fringe) of alternate path segments in case of A*. Therefore, at each step, we remove the node with the lowest f(x) value from the queue until reaching a goal square.

%----------------------------------------------------------------------------------------
%	Hill-climbing
%----------------------------------------------------------------------------------------

\subsection{Hill-climbing algorithm:}

As a local search algorithm, hill-climbing starts by exploring its neighbors and pick a candidate with the highest value evaluated by its objective function ($Manhattan\_distance * -1$) then compare the value of the neighbor node with its current node. If the neighbor node has a higher value the neighbor becomes the current node and repeat, otherwise it will exit the explore and compare loop, stop search and return a solution if the current node is the goal or failure if it is not. This often leads to improvement in search speed since it embraces the goal to always find a higher value neighboring square compare to its own without wasting time considering the currently poorer options and as a consequence it will get stuck on a locally optimal point. \\

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.9]{images/hillclimb1.png}
  \caption{Hill-climbing search with a block between two points}
  \label{fig:hillClimbing}
\end{figure}

\noindent
Hence, in our grid map if there is an obstacle lying on the path to the goal node, the steepest-ascent hill-climbing we have implemented here will stop immediately as seen in the Figure~\ref{fig:hillClimbing}.

%----------------------------------------------------------------------------------------
%	Simulated annealing
%----------------------------------------------------------------------------------------

\subsection{Simulated annealing algorithm:}

Taking the advantage of search speech by not looking far ahead while trying to address the problem of getting stuck in local optima of a typical hill-climbing, simulated annealing starts by choosing a random successor and move to the square if it has a higher value than current position. Otherwise, accept the move only when the probability ($e^{\Delta E/T}$) is greater than a pseudorandomly generated number between $[0, 1]$. At the start, $T$ the temperature was initialized to $1000$ and the cooling schedule gradually decreases the temperature $T$ in each time step until $0$ and the search terminates if the goal hasn't been found. As temperature is getting lower the "bad" moves are becoming more unlikely driving the search to consider the moves more promising toward reaching the goal. \\

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.9]{images/sa1.png}
  \caption{Simulated annealing with a block between two points}
  \label{fig:simulatedAnnealing}
\end{figure}

\paragraph{Cooling schedule:} Due to the randomness in picking a move with probability simulated annealing can manage to overcome local optima however in the hope to always reach the goal it very depends on the cooling schedule implementation. When the temperature decays too fast it will not be able to find the goal, but when the temperature decaying rate is too low the algorithm will take too many unnecessary trial and error moves and if there is no way to get to the goal node this exhaustive loop will still carry on as long as the temperature is greater than zero. Hence choosing the right cooling schedule function and its parameter is crucial to determine the productivity of the algorithm and the varying in size and characteristics of the problem space directly affect the decision to be made. In our situation, we use Linear Multiplicative Monotonic function \\

\begin{equation} \label{eq:linearMultiplicative}
T_k = \frac{T_0}{1 + \alpha \cdot k}, \quad \alpha > 0
\end{equation}
\\
\noindent where we set $T_0 = 1000$ and $\alpha = 0.1$, so the maximum loop here is 9991 for our simulated annealing algorithm. You can easily solve for $\alpha$ by tweaking the equation~\ref{eq:linearMultiplicative} to be \\

\begin{equation}
\alpha = \left(T_0-1\right) \cdot \frac{1}{k-1}
\end{equation}
\\
\noindent where $k$ is the maximum loop for your simulated annealing algorithm. \\

\noindent In term of Multiplicative cooling function, there are 3 other available choices including Exponential multiplicative cooling, Logarithmical multiplicative cooling, and Quadratic multiplicative cooling all of which not only consume more computational resource comparing to the linear function we are using but predictable nature of linearity also allows us to fine tune for an optimal $\alpha$ given discrete state space like our $22 \times 32$ grid map.

\paragraph{Use of grids:} Grids are widely used in games to represent a playground such as maps (Warcraft), playing surfaces (pool, tennis, poker), playing fields (baseball, football), boards (chess, Monopoly, Connect Four), and abstract spaces (Tetris). \\

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.6]{images/square-grid.png}
  \caption{Square grida}
\end{figure}

\noindent We build grids by repeating simple shapes. A square grid is the most common type. It is the simplest type and very easy to work with, therefore the most common type of grid. We can represent locations using simple coordinates (x, y) system. The square coordinate system is the same even if your map squares are angled on screen in an isometric or axonometric projection. The default choice of heuristic function on a grid is understandably Manhattan distance heuristics, because of its block-type structure.

%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------

\section{Results and Analysis}

The results we have obtained, after running these algorithms individually both with and without a block between the points A and B, are pretty astonishing and is a pleasure for anyone to watch how these algorithms get the job done through such distinctive methodologies.\\

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.9]{images/bfs1.png}
  \caption{BFS with a block between two points}
\end{figure}

\noindent Let us compare the six algorithms in an exactly same problem case with a single square block in between the two points. \\

\noindent As we can see here, in breadth-first search algorithm, all the nodes are expanded at a given depth in the search tree before any nodes at the next level are expanded. Therefore the shape of the search space covered is guaranteed to be a square on a grid and the expanded node is the largest in case of BFS. The CPU execution time is also the longest since the algorithm is doing an exhaustive search to reach the destination node. We can see how blind (and wasteful) an uninformed search actually is. Breadth-first search is guaranteed to find the optimal path, so we can see that the path-cost is 14 in above case. \\

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.9]{images/dfs1.png}
  \caption{DFS with a block between two points}
\end{figure}

\noindent As we can see here, DFS expands the deepest node in the current frontier. Therefore the path cost is quite high in this example and the CPU execution time as well. It also expanded much more nodes than BFS, therefore proving that DFS is non-optimal. \\

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.9]{images/A1.png}
  \caption{A* with a block between two points}
\end{figure}

\noindent We can see from the above picture how smart the heuristic search compared to the uninformed search is. A* actually has a sense of direction to look for the destination and is very effective in finding it. The length of the path is same as BFS, therefore guarantees an optimal path, because of an admissible heuristic function. We can see that the expanded node is greatly reduced and the CPU execution time accordingly. \\

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.9]{images/greedy1.png}
  \caption{Greedy best-first search with a block between two points}
\end{figure}

\noindent The greedy best-first search is the most effective in this case with a minimum expanded nodes of 14, thereby having the least CPU execution time. This proves that a greedy algorithm can be very effective in the right circumstance. Instead of selecting the vertex closest to the starting point, it selects the vertex closest to the goal. Greedy Best-First-Search is not guaranteed to find a shortest path. However, it runs much quicker than A* algorithm. \\

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.9]{images/hillclimb1.png}
  \caption{Hill-climbing search with a block between two points}
\end{figure}

\noindent As we can see (in Figure 6), a local search algorithm operate using a single current node (rather than multiple paths) and generally move only to neighbors of that node. Also the paths followed by the search are not retained. So we can testify from above that the hill-climbing search is simply a loop that continually moves in the direction of increasing value – that is, uphill. And since there’s an obstacle, it failed to find the path to the destination, because it simply did not keep track of alternative routes. Hence we can see the clear limitations of the hill-climbing search here. \\

\begin{figure}[h!]
  \centering
    \includegraphics[scale=.9]{images/sa1.png}
  \caption{Simulated annealing with a block between two points}
\end{figure}

\noindent Simulated annealing is the most ineffective choice as per this example as the path length is 406 steps as shown. However, the CPU execution time and the expanded node are much less than uninformed search algorithms because of its randomness.


%----------------------------------------------------------------------------------------
%	SECTION 4
%----------------------------------------------------------------------------------------

\section{Conclusion}

So the obvious question is "which algorithm should we use for finding paths on a game map?"

\begin{itemize}
\item If you want to find paths from or to all locations, use Breadth First Search.
\item If you want to find paths to one location, use Greedy Best First Search or A*. We would prefer A* in most cases since it is optimal.
\end{itemize}

\noindent What about optimal paths? Breadth First Search is guaranteed to find the shortest path given the input graph. Greedy Best First Search is not. A* is guaranteed to find the shortest path if the heuristic is never larger than the true distance. As the heuristic becomes larger, A* turns into Greedy Best First Search.\\

\noindent What about performance? The best thing to do is to eliminate unnecessary locations in your graph. Reducing the size of the graph helps all the graph search algorithms. It also can be noticed that simpler queues run faster. Greedy Best First Search typically runs faster but doesn’t produce optimal paths. A* is a good choice for most pathfinding needs.

\newpage

%$T_k = \frac{T_0}{1 + \alpha \cdot k}, \quad \alpha > 0$

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

%\bibliographystyle{apalike}

%\bibliography{sample}

%----------------------------------------------------------------------------------------


\end{document}